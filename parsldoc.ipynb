{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43331641-24d4-421c-b1b3-4bf192b18329",
   "metadata": {},
   "source": [
    "## ParslDock workflow \n",
    "\n",
    "This notebook shows how to implement a parallel, machine learning protein docking workflow. The goal of the notebook is to show how machine learning can be used as a lightweight surrogate for computationally expensive protein docking simulations. \n",
    "\n",
    "Protein docking aism to predict the orientation and position of two moluecules, where one molecule is a protein, and the other is a protein or a smaller molecule (ligand). Docking is commonly used in structure-based drug design, as it can predict the strength of docking between target small molecule ligands (drugs) to target binding site (receptors). Protein docking played an important role in the race to identify COVID-19 theurapeutics. \n",
    "\n",
    "Docking can be computed using various simulation packages (here we use [AutoDock](https://vina.scripps.edu/)); however, these simulations can be computationally expensive and the search space of potential molecules is enormous. Therefore, given finite compute capacity, we want to carefully choose which molecules to explore. For this purpose we use machine learning to predict molecules with strong docking scores based on on previous computations (a process often called active learning). The resulting ML-in-the-loop workflow proceeds as follows.\n",
    "\n",
    "<< INSERT FIGURE >>\n",
    "\n",
    "We use Parsl to implement and execute the docking process in parallel. Parsl allows us to establish dependencies in the workflow and to execute the workflow on arbitrary computing infrastructure, from laptops to supercomputers. We show how Parsl's integration with Python's native concurrency library (i.e., concurrent.futures) let you write applications that dynamically respond to the completion of asynchronous tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aadd079-44e5-45e8-b77f-a1bf894e18e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "autodocktools_path = os.getenv(\"MGLTOOLS_HOME\") \n",
    "\n",
    "def smi_txt_to_pdb(smiles, pdb_file):\n",
    "    \"\"\"Converts SMILE text to a PDB file.\n",
    "    Parameters\n",
    "    ----------\n",
    "    smiles_file : str\n",
    "        Input SMILES text.\n",
    "    pdb_file : str\n",
    "        Output PDB file.\n",
    "    forcefield : str, optional\n",
    "        orcefield to use for 3D conformation generation\n",
    "        (either \"mmff\" or \"etkdg\"), by default \"mmff\".\n",
    "    \"\"\"\n",
    "    from rdkit import Chem\n",
    "    from rdkit.Chem import AllChem\n",
    "    \n",
    "    # Convert SMILES to RDKit molecule object\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    # Add hydrogens to the molecule\n",
    "    mol = Chem.AddHs(mol)\n",
    "    # Generate a 3D conformation for the molecule\n",
    "    AllChem.EmbedMolecule(mol)\n",
    "    AllChem.MMFFOptimizeMolecule(mol)\n",
    "    \n",
    "    # Write the molecule to a PDB file\n",
    "    writer = Chem.PDBWriter(pdb_file)\n",
    "    writer.write(mol)\n",
    "    writer.close()\n",
    "\n",
    "def set_element(input_pdb_file, output_pdb_file):\n",
    "    \"\"\"Set the element of each atom in a PDB file.\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_pdb_file : str\n",
    "        Input PDB file.\n",
    "    output_pdb_file : str\n",
    "        Output PDB file.\n",
    "    \"\"\"\n",
    "    tcl_script = \"set_element.tcl\"\n",
    "    command = (\n",
    "        f\"vmd -dispdev text -e {tcl_script} -args {input_pdb_file} {output_pdb_file}\"\n",
    "    )\n",
    "    #print(command)\n",
    "    result = subprocess.check_output(command.split())\n",
    "    return result\n",
    "\n",
    "\n",
    "def pdb_to_pdbqt(pdb_file, pdbqt_file, ligand= True):\n",
    "    \"\"\"Convert a PDB file to a PDBQT file for a receptor.\n",
    "    Parameters\n",
    "    ----------\n",
    "    pdb_file : str\n",
    "    Input PDB file.\n",
    "        pdbqt_file : str\n",
    "    Output PDBQT file.\n",
    "        autodocktools_path : str\n",
    "    Path to AutoDockTools folder.\n",
    "    ligand : bool, optional\n",
    "    Whether the PDB file is a ligand or receptor, by default True.\n",
    "    \"\"\"\n",
    "\n",
    "    # Select the correct settings for ligand or receptor preparation\n",
    "    script, flag = (\n",
    "        (\"prepare_ligand4.py\", \"l\") if ligand else (\"prepare_receptor4.py\", \"r\")\n",
    "    )\n",
    "\n",
    "    command = (\n",
    "        #f\"{Path(autodocktools_path)  / 'bin/pythonsh'}\"\n",
    "        f\"{'python2'}\"\n",
    "        f\" {Path(autodocktools_path) / 'MGLToolsPckgs/AutoDockTools/Utilities24' / script}\"\n",
    "        f\" -{flag} {pdb_file}\"\n",
    "        f\" -o {pdbqt_file}\"\n",
    "        f\" -U nphs_lps_waters\"\n",
    "    )\n",
    "    #print(command)\n",
    "    result = subprocess.check_output(command.split(), encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "def make_autodock_vina_config(\n",
    "    input_receptor_pdbqt_file: str,\n",
    "    input_ligand_pdbqt_file: str,\n",
    "    output_conf_file: str,\n",
    "    output_ligand_pdbqt_file: str,\n",
    "    center: Tuple[float, float, float],\n",
    "    size: Tuple[int, int, int],\n",
    "    exhaustiveness: int = 20,\n",
    "    num_modes: int = 20,\n",
    "    energy_range: int = 10,\n",
    ") -> None:\n",
    "    \"\"\"Make a configuration file for AutoDock Vina.\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_receptor_pdbqt_file : str\n",
    "        Input receptor PDBQT file.\n",
    "    input_ligand_pdbqt_file : str\n",
    "        Input ligand PDBQT file.\n",
    "    output_conf_file : str\n",
    "        Output configuration file.\n",
    "    output_ligand_pdbqt_file : str\n",
    "        Output ligand PDBQT file.\n",
    "    center : Tuple[float, float, float]\n",
    "        Center of the search space.\n",
    "    size : Tuple[int, int, int]\n",
    "        Size of the search space.\n",
    "    exhaustiveness : int, optional\n",
    "        Exhaustiveness of the search, by default 20.\n",
    "    num_modes : int, optional\n",
    "        Number of binding modes to generate, by default 20.\n",
    "    energy_range : int, optional\n",
    "        Energy range, by default 10.\n",
    "    \"\"\"\n",
    "    # Format configuration file\n",
    "    file_contents = (\n",
    "        f\"receptor = {input_receptor_pdbqt_file}\\n\"\n",
    "        f\"ligand = {input_ligand_pdbqt_file}\\n\"\n",
    "        f\"center_x = {center[0]}\\n\"\n",
    "        f\"center_y = {center[1]}\\n\"\n",
    "        f\"center_z = {center[2]}\\n\"\n",
    "        f\"size_x = {size[0]}\\n\"\n",
    "        f\"size_y = {size[1]}\\n\"\n",
    "        f\"size_z = {size[2]}\\n\"\n",
    "        f\"exhaustiveness = {exhaustiveness}\\n\"\n",
    "        f\"num_modes = {num_modes}\\n\"\n",
    "        f\"energy_range = {energy_range}\\n\"\n",
    "        f\"out = {output_ligand_pdbqt_file}\\n\"\n",
    "        #f\"log = {output_log_file}\\n\"\n",
    "    )\n",
    "    # Write configuration file\n",
    "    with open(output_conf_file, \"w\") as f:\n",
    "        f.write(file_contents)\n",
    "\n",
    "\n",
    "def autodock_vina(config_file, num_cpu = 8):\n",
    "    \"\"\"Run AutoDock Vina.\n",
    "\n",
    "    Parameters\n",
    "     ----------\n",
    "    config_file : str\n",
    "        Path to AutoDock Vina configuration file.\n",
    "    num_cpu : int, optional\n",
    "        Number of CPUs to use, by default 8.\n",
    "    \"\"\"\n",
    "    autodock_vina_exe = \"vina\"\n",
    "    try:\n",
    "        command = f\"{autodock_vina_exe} --config {config_file} --cpu {num_cpu}\"\n",
    "        #print(command)\n",
    "        result = subprocess.check_output(command.split(), encoding=\"utf-8\")\n",
    "\n",
    "        # find the last row of the table and extract the affinity score\n",
    "        result_list = result.split('\\n')\n",
    "        last_row = result_list[-3]\n",
    "        score = last_row.split()\n",
    "        return float(score[1])\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Command '{e.cmd}' returned non-zero exit status {e.returncode}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49ca31a-a92f-4582-bd4a-64995685a3a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## simple test that everything is working\n",
    "\n",
    "def docking_workflow(smiles):\n",
    "    import uuid\n",
    "    import os\n",
    "    fname = uuid.uuid4().hex\n",
    "    \n",
    "    smi_txt_to_pdb(smiles, '%s.pdb' % fname)\n",
    "    set_element('%s.pdb' % fname, '%s-coords.pdb' % fname) \n",
    "    pdb_to_pdbqt('%s-coords.pdb' % fname, '%s-coords.pdbqt' % fname, True)\n",
    "    \n",
    "    receptor = '1iep_receptor.pdbqt'\n",
    "    exhaustiveness = 1\n",
    "    num_cpu = 1\n",
    "    #specific to 1iep receptor\n",
    "    cx, cy, cz=15.614, 53.380, 15.455\n",
    "    sx, sy, sz = 20, 20, 20\n",
    "\n",
    "    make_autodock_vina_config(receptor, '%s-coords.pdbqt' % fname, '%s-config.txt' % fname, \n",
    "                              '%s-out.pdb' % fname,\n",
    "                          (cx, cy, cz), (sx, sy, sz), exhaustiveness)\n",
    "    \n",
    "    score = autodock_vina('%s-config.txt' % fname, num_cpu)\n",
    "    \n",
    "    # remove files.. \n",
    "    os.remove('%s.pdb' % fname)\n",
    "    os.remove('%s-coords.pdbqt' % fname)\n",
    "    os.remove('%s-config.txt' % fname)\n",
    "    os.remove('%s-out.pdb' % fname)\n",
    "\n",
    "    return score\n",
    "\n",
    "print(docking_workflow(\"CC1(C2C1C(N(C2)C(=O)C(C(C)(C)C)NC(=O)C(F)(F)F)C(=O)NC(CC3CCNC3=O)C#N)C\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8cd599-4427-4793-a855-545dc6365d01",
   "metadata": {},
   "source": [
    "# Part 1: Manual ParslDock Workflow\n",
    "\n",
    "Before creating a parallel workflow, we first go through the steps to take a target molecule and compute the docking score against a target receptor. \n",
    "\n",
    "Molecules can be represented as strings using the \"Simplified Molecular Input Line Entry System\" format. For example, Paxalovid can be represented as \"CC1(C2C1C(N(C2)C(=O)C(C(C)(C)C)NC(=O)C(F)(F)F)C(=O)NC(CC3CCNC3=O)C#N)C\".\n",
    "\n",
    "#### 1. Convert SMILES to PDB\n",
    "\n",
    "We first need to convert the molecule to a PDB file that can be used in the docking simulation. Protein Data Bank (PDB) format is a standard for files containing atomic coordinates. We use [RDKit](https://www.rdkit.org/), a collection of cheminformatics and machine-learning software for molecular sciences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43446d0-68f2-430a-88ae-cc0e5a848fc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smi_txt_to_pdb('CC1(C2C1C(N(C2)C(=O)C(C(C)(C)C)NC(=O)C(F)(F)F)C(=O)NC(CC3CCNC3=O)C#N)C', \n",
    "               'paxalovid-molecule.pdb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad8ee65-e0c1-412b-bd3d-fe683f90409f",
   "metadata": {},
   "source": [
    "#### 2. Add coordinates\n",
    "\n",
    "We then add coordinates to the PBD file using [VMD](https://www.ks.uiuc.edu/Research/vmd/). VMD is a molecular visualization program for displaying, animating, and analyzing large biomolecular systems using 3-D graphics and built-in scripting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dc00c3-0171-4261-a52c-fef6f370f6cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_element('paxalovid-molecule.pdb', 'paxalovid-molecule-coords.pdb') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb801bf-2658-4dda-a38e-4066eb4aab8e",
   "metadata": {},
   "source": [
    "### 3. Convert to PDBQT\n",
    "\n",
    "We now convert the PBD file to PDBQT format. PDBQT is a similar file format to PDB, but it a also encodes connectivity (i.e. bonds). We use AutoDockTools to do the conversion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ca2d81-8bb8-4009-806d-b0156633933c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdb_to_pdbqt('paxalovid-molecule-coords.pdb', 'paxalovid-molecule-coords.pdbqt', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787f7931-90b0-442e-97b1-4629ed8a5494",
   "metadata": {},
   "source": [
    "#### 4. Configure Docking simulation\n",
    "\n",
    "We create a configuration file for [AutoDock Vina](https://vina.scripps.edu/) by descrbing the target receptor and setting coordinate bounds for the docking experiment. In this case, we use the 1iep receptor.  We can set properties including the exhaustiveness, which captions the number of monte carlo simulations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8204706-8981-4787-8d57-bc43a2933469",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "receptor = '1iep_receptor.pdbqt'\n",
    "ligand = 'paxalovid-molecule-coords.pdbqt'\n",
    "\n",
    "exhaustiveness = 1\n",
    "#specific to 1iep receptor\n",
    "cx, cy, cz=15.614, 53.380, 15.455\n",
    "sx, sy, sz = 20, 20, 20\n",
    "\n",
    "make_autodock_vina_config(receptor, ligand, 'paxalovid-config.txt', ligand,  (cx, cy, cz), (sx, sy, sz), exhaustiveness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63eb399-addf-43d9-8846-784e64d82670",
   "metadata": {},
   "source": [
    "#### 5. Compute the Docking score\n",
    "\n",
    "Finally, we use [AutoDock Vina](https://vina.scripps.edu/) to compute the docking score. We use the configuration file above and run the simulation, we take the final score produced after several rounds of simulation. \n",
    "\n",
    "The docking score captures the potential energy change when the protein and ligand are docked. A strong binding is represented by a negative score, weaker (or no) binders are represented by positive scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facbfbeb-34c9-42cf-b847-e20b30ab0650",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "score = autodock_vina(\"paxalovid-config.txt\", 1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6eb0c9-8d27-48da-8a0e-e252648cea35",
   "metadata": {},
   "source": [
    "## Part 2: Parallelize the workflow\n",
    "\n",
    "When selecting drug candidates we have an enormous search space of molecules we wish to consider. We consider here a small list of 1000 orderable molecules with the aim to run the workflow across many cores concurrently. \n",
    "\n",
    "We use the Parsl parallel programming library to represent the workflow in Parsl. We string together the steps above so that each step will execute after the proceeding step has completed. Parsl represents each step as an asynchronous \"app\". When an app is called, it is intercepted by Parsl and added to a queue of tasks to execute. The application is returned a future that can be used to reference the result (note: the program will not block on that future and can continue executing waiting for the result to complete). Parsl allows us to easily parallelize across cores on a multi-core computer or across computers in the case of a cloud, cluster, or supercomputer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682dc28b-3d59-4e49-9d01-a85c236231af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "smi_file_name_ligand = 'dataset_orz_original_1k.csv'\n",
    "\n",
    "search_space = pd.read_csv(smi_file_name_ligand)\n",
    "search_space = search_space[['TITLE','SMILES']]\n",
    "\n",
    "print(search_space.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5add47-d5f2-4f0c-a7d3-575e466d06a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from parsl import python_app, bash_app\n",
    "\n",
    "@python_app\n",
    "def parsl_smi_to_pdb(smiles, outputs=[]):\n",
    "    from rdkit import Chem\n",
    "    from rdkit.Chem import AllChem\n",
    "    \n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    mol = Chem.AddHs(mol)\n",
    "\n",
    "    AllChem.EmbedMolecule(mol)\n",
    "    AllChem.MMFFOptimizeMolecule(mol)\n",
    "    \n",
    "    writer = Chem.PDBWriter(outputs[0].filepath)\n",
    "    writer.write(mol)\n",
    "    writer.close()\n",
    "    \n",
    "    return True\n",
    "\n",
    "@bash_app\n",
    "def parsl_set_element(input_pdb, outputs=[]):\n",
    "   \n",
    "    tcl_script = \"set_element.tcl\"\n",
    "    command = (\n",
    "        f\"vmd -dispdev text -e {tcl_script} -args {input_pdb} {outputs[0]}\"\n",
    "    )\n",
    "    return command\n",
    "\n",
    "@bash_app\n",
    "def parsl_pdb_to_pdbqt(input_pdb, outputs=[], ligand = True):\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    autodocktools_path = os.getenv(\"MGLTOOLS_HOME\") \n",
    "\n",
    "    # Select the correct settings for ligand or receptor preparation\n",
    "    script, flag = (\n",
    "        (\"prepare_ligand4.py\", \"l\") if ligand else (\"prepare_receptor4.py\", \"r\")\n",
    "    )\n",
    "\n",
    "    command = (\n",
    "        f\"{'python2'}\"\n",
    "        f\" {Path(autodocktools_path) / 'MGLToolsPckgs/AutoDockTools/Utilities24' / script}\"\n",
    "        f\" -{flag} {input_pdb}\"\n",
    "        f\" -o {outputs[0]}\"\n",
    "        f\" -U nphs_lps_waters\"\n",
    "    )\n",
    "    return command\n",
    "\n",
    "@python_app\n",
    "def parsl_make_autodock_config(\n",
    "    input_receptor,\n",
    "    input_ligand,\n",
    "    output_pdbqt,\n",
    "    outputs=[], \n",
    "    center=(15.614, 53.380, 15.455), size=(20, 20, 20),\n",
    "    exhaustiveness=1, num_modes= 20, energy_range = 10,):\n",
    "   \n",
    "    # Format configuration file\n",
    "    file_contents = (\n",
    "        f\"receptor = {input_receptor}\\n\"\n",
    "        f\"ligand = {input_ligand}\\n\"\n",
    "        f\"center_x = {center[0]}\\n\"\n",
    "        f\"center_y = {center[1]}\\n\"\n",
    "        f\"center_z = {center[2]}\\n\"\n",
    "        f\"size_x = {size[0]}\\n\"\n",
    "        f\"size_y = {size[1]}\\n\"\n",
    "        f\"size_z = {size[2]}\\n\"\n",
    "        f\"exhaustiveness = {exhaustiveness}\\n\"\n",
    "        f\"num_modes = {num_modes}\\n\"\n",
    "        f\"energy_range = {energy_range}\\n\"\n",
    "        f\"out = {output_pdbqt}\\n\"\n",
    "        #f\"log = {output_log_file}\\n\"\n",
    "    )\n",
    "    # Write configuration file\n",
    "    with open(outputs[0].filepath, \"w\") as f:\n",
    "        f.write(file_contents)\n",
    "        \n",
    "    return True\n",
    "    \n",
    "@python_app\n",
    "def parsl_autodock_vina(input_config, num_cpu = 1):\n",
    "    import subprocess\n",
    "\n",
    "    autodock_vina_exe = \"vina\"\n",
    "    try:\n",
    "        command = f\"{autodock_vina_exe} --config {input_config} --cpu {num_cpu}\"\n",
    "        #print(command)\n",
    "        result = subprocess.check_output(command.split(), encoding=\"utf-8\")\n",
    "\n",
    "        # find the last row of the table and extract the affinity score\n",
    "        result_list = result.split('\\n')\n",
    "        last_row = result_list[-3]\n",
    "        score = last_row.split()\n",
    "        return float(score[1])\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return (f\"Command '{e.cmd}' returned non-zero exit status {e.returncode}\")\n",
    "    except Exception as e:\n",
    "        return (f\"Error: {e}\")\n",
    "\n",
    "@python_app\n",
    "def cleanup(dock_future, pdb, pdb_coords, pdb_qt, autodoc_config, docking):\n",
    "    os.remove(pdb)\n",
    "    os.remove(pdb_coords)\n",
    "    os.remove(pdb_qt)\n",
    "    os.remove(autodoc_config)\n",
    "    os.remove(docking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c9ad8e-347e-4c66-86d6-753b5f18ba1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from parsl.executors import HighThroughputExecutor\n",
    "from parsl.config import Config\n",
    "import parsl\n",
    "\n",
    "config = Config(\n",
    "    executors=[HighThroughputExecutor(\n",
    "        max_workers=4, # Allows a maximum of two workers\n",
    "        cpu_affinity='block' # Prevents workers from using the same cores\n",
    "    )]\n",
    ")\n",
    "parsl.clear()\n",
    "parsl.load(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e744e43-e8ba-4dbe-8495-2fb2cfe648a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from parsl.data_provider.files import File as PFile\n",
    "smi_future = parsl_smi_to_pdb('CC1(C2C1C(N(C2)C(=O)C(C(C)(C)C)NC(=O)C(F)(F)F)C(=O)NC(CC3CCNC3=O)C#N)C',\n",
    "               outputs=[PFile('parsl-pax-molecule.pdb')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e03aa37-fbe5-4595-a5dc-80309f27e790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "element_future = parsl_set_element(smi_future.outputs[0], outputs=[PFile('parsl-pax-molecule-coords.pdb')]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fecff8d-5a51-418c-af9b-82aff492641e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdbqt_future = parsl_pdb_to_pdbqt(element_future.outputs[0], outputs=[PFile('parsl-pax-molecule-coords.pdbqt')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b6250a-bab5-4f3f-b27f-16f063ecf6d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "receptor = '1iep_receptor.pdbqt'\n",
    "   \n",
    "config_future = parsl_make_autodock_config(PFile(receptor), pdbqt_future.outputs[0], \n",
    "                                     'parsl-pax-molecule-out.pdb', outputs=[PFile('parsl-pax-molecule-config.txt')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fde06f5-9620-4bb0-a899-d57012feb479",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dock_future = parsl_autodock_vina(config_future.outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8034cf0c-aca7-44a3-b5e7-95ca8aa5769d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dock_future.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15da8a89-58a4-416a-81f4-5349483f273e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleanup(dock_future, smi_future.outputs[0], element_future.outputs[0], pdbqt_future.outputs[0], \n",
    "            config_future.outputs[0], PFile('parsl-pax-molecule-out.pdb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4fff1b-36dd-48c9-b7eb-8f3b7f9807ff",
   "metadata": {},
   "source": [
    "# Part 3: Create the ML Loop\n",
    "\n",
    "Our next step is to create a machine learning model to estimate the outcome of new computations (i.e., docking simulations) and use it to rapidly scan the search space.\n",
    "\n",
    "To start, let's make a function that uses our prior simulations to train a model. We are going to use RDKit and scikit-learn to train a nearest-neighbor model that uses Morgan fingerprints to define similarity. In short, the function trains a model that first populates a list of certain substructures (Morgan fingerprints, specifically) and then trains a model which predicts the docking score of a new molecule by averaging those with the most similar substructures.\n",
    "\n",
    "Note: as we use a simple model and train on a small set of training data it is likely that the predictions are not very accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90825496-88a9-450c-985f-bb9d7c25c5e1",
   "metadata": {},
   "source": [
    "First let's run a number of simulations to use to train the ML model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c89e63-becb-4abd-bfad-ff8564d095c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from time import monotonic\n",
    "import uuid\n",
    "\n",
    "train_data = []\n",
    "futures = []\n",
    "while len(futures) < 5: \n",
    "    \n",
    "    selected = search_space.sample(1).iloc[0]\n",
    "    title, smiles = selected['TITLE'], selected['SMILES'] \n",
    "    \n",
    "    # workflow\n",
    "    fname = uuid.uuid4().hex\n",
    "    \n",
    "    smi_future = parsl_smi_to_pdb(smiles, outputs=[PFile('%s.pdb' % fname)])\n",
    "    element_future = parsl_set_element(smi_future.outputs[0], outputs=[PFile('%s-coords.pdb'% fname)]) \n",
    "    pdbqt_future = parsl_pdb_to_pdbqt(element_future.outputs[0], outputs=[PFile('%s-coords.pdbqt' % fname)])\n",
    "    config_future = parsl_make_autodock_config(PFile(receptor), pdbqt_future.outputs[0], \n",
    "                                     '%s-out.pdb' % fname, outputs=[PFile('%s-config.txt' % fname)])\n",
    "    dock_future = parsl_autodock_vina(config_future.outputs[0])\n",
    "    cleanup(dock_future, smi_future.outputs[0], element_future.outputs[0], pdbqt_future.outputs[0], \n",
    "            config_future.outputs[0], PFile('%s-out.pdb' % fname))\n",
    "\n",
    "    futures.append((smiles, dock_future))\n",
    "\n",
    "\n",
    "# wait for all the workflows to complete\n",
    "for smiles, future in futures:\n",
    "    result = future.result()\n",
    "    print(f'Computation for {smiles} succeeded: {result}')\n",
    "    \n",
    "    train_data.append({\n",
    "            'smiles': smiles,\n",
    "            'score': result,\n",
    "            'time': monotonic()\n",
    "    })\n",
    "    \n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd02de38-f4c7-4a23-977d-49c9eb81a97a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "_pool = ProcessPoolExecutor(max_workers=1)\n",
    "\n",
    "def compute_morgan_fingerprints(smiles: str, fingerprint_length: int, fingerprint_radius: int):\n",
    "    from rdkit import Chem, DataStructs\n",
    "    from rdkit.Chem import AllChem\n",
    "    \"\"\"Get Morgan Fingerprint of a specific SMILES string.\n",
    "    Adapted from: <https://github.com/google-research/google-research/blob/\n",
    "    dfac4178ccf521e8d6eae45f7b0a33a6a5b691ee/mol_dqn/chemgraph/dqn/deep_q_networks.py#L750>\n",
    "    Args:\n",
    "      graph (str): The molecule as a SMILES string\n",
    "      fingerprint_length (int): Bit-length of fingerprint\n",
    "      fingerprint_radius (int): Radius used to compute fingerprint\n",
    "    Returns:\n",
    "      np.array. shape = [hparams, fingerprint_length]. The Morgan fingerprint.\n",
    "    \"\"\"\n",
    "    # Parse the molecule\n",
    "    molecule = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    # Compute the fingerprint\n",
    "    fingerprint = AllChem.GetMorganFingerprintAsBitVect(\n",
    "        molecule, fingerprint_radius, fingerprint_length)\n",
    "    arr = np.zeros((1,), dtype=bool)\n",
    "\n",
    "    # ConvertToNumpyArray takes ~ 0.19 ms, while\n",
    "    # np.asarray takes ~ 4.69 ms\n",
    "    DataStructs.ConvertToNumpyArray(fingerprint, arr)\n",
    "    return arr\n",
    "\n",
    "\n",
    "class MorganFingerprintTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Class that converts SMILES strings to fingerprint vectors\"\"\"\n",
    "\n",
    "    def __init__(self, length: int = 256, radius: int = 4):\n",
    "        self.length = length\n",
    "        self.radius = radius\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # Do need to do anything\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"Compute the fingerprints\n",
    "        \n",
    "        Args:\n",
    "            X: List of SMILES strings\n",
    "        Returns:\n",
    "            Array of fingerprints\n",
    "        \"\"\"\n",
    "        \n",
    "        fps = []\n",
    "        for x in X: \n",
    "            fps.append(compute_morgan_fingerprints(x, self.length, self.radius))\n",
    "            \n",
    "        return fps\n",
    "        \n",
    "        # my_func = partial(compute_morgan_fingerprints,\n",
    "        #                   fingerprint_length=self.length,\n",
    "        #                   fingerprint_radius=self.radius)\n",
    "        # fing = _pool.map(my_func, X, chunksize=2048)\n",
    "        # return np.vstack(fing)\n",
    "\n",
    "def train_model(training_data):\n",
    "    \"\"\"Train a machine learning model using Morgan Fingerprints.\n",
    "    \n",
    "    Args:\n",
    "        train_data: Dataframe with a 'smiles' and 'score' column\n",
    "            that contains molecule structure and docking score, respectfully.\n",
    "    Returns:\n",
    "        A trained model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Imports for python functions run remotely must be defined inside the function\n",
    "    from sklearn.neighbors import KNeighborsRegressor\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    \n",
    "    \n",
    "    model = Pipeline([\n",
    "        ('fingerprint', MorganFingerprintTransformer()),\n",
    "        ('knn', KNeighborsRegressor(n_neighbors=4, weights='distance', metric='jaccard', n_jobs=-1))  # n_jobs = -1 lets the model run all available processors\n",
    "    ])\n",
    "    \n",
    "    return model.fit(training_data['smiles'], training_data['score'])\n",
    "\n",
    "def run_model(model, smiles):\n",
    "    \"\"\"Run a model on a list of smiles strings\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model that takes SMILES strings as inputs\n",
    "        smiles: List of molecules to evaluate\n",
    "    Returns:\n",
    "        A dataframe with the molecules and their predicted outputs\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    pred_y = model.predict(smiles)\n",
    "    return pd.DataFrame({'smiles': smiles, 'score': pred_y})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d03da92-08c3-4ebd-b5ae-7e26b07cab32",
   "metadata": {},
   "source": [
    "Now let's train the model and run simulations over the remaining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f12eb73-901a-4068-b725-9d169050ffc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_df = pd.DataFrame(train_data)\n",
    "m = train_model(training_df)\n",
    "predictions = run_model(m, search_space['SMILES'])\n",
    "predictions.sort_values('score', ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6ac743-6a17-4c7d-a81a-20f39ec1f390",
   "metadata": {},
   "source": [
    "# Part 4: Putting it all together\n",
    "\n",
    "We now combine the parallel ParslDock workflow with the machine learning algorithm in an iterative fashion. Here each round will 1) train a machine learning model based on previous simulations; 2) apply the machine learning model to all remaining molecules; 3) select the top predicted scores; 4) run simulations on the top molecules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef200970-d436-49de-8561-9173c8587d91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "futures = []\n",
    "train_data = []\n",
    "smiles_simulated = []\n",
    "initial_count = 5\n",
    "num_loops = 3\n",
    "batch_size = 3\n",
    "\n",
    "# start with an initial set of random smiles\n",
    "for i in range(initial_count):\n",
    "    selected = search_space.sample(1).iloc[0]\n",
    "    title, smiles = selected['TITLE'], selected['SMILES'] \n",
    "\n",
    "    # workflow\n",
    "    fname = uuid.uuid4().hex\n",
    "    \n",
    "    smi_future = parsl_smi_to_pdb(smiles, outputs=[PFile('%s.pdb' % fname)])\n",
    "    element_future = parsl_set_element(smi_future.outputs[0], outputs=[PFile('%s-coords.pdb'% fname)]) \n",
    "    pdbqt_future = parsl_pdb_to_pdbqt(element_future.outputs[0], outputs=[PFile('%s-coords.pdbqt' % fname)])\n",
    "    config_future = parsl_make_autodock_config(PFile(receptor), pdbqt_future.outputs[0], \n",
    "                                     '%s-out.pdb' % fname, outputs=[PFile('%s-config.txt' % fname)])\n",
    "    dock_future = parsl_autodock_vina(config_future.outputs[0])\n",
    "    cleanup(dock_future, smi_future.outputs[0], element_future.outputs[0], pdbqt_future.outputs[0], \n",
    "            config_future.outputs[0], PFile('%s-out.pdb' % fname))\n",
    "\n",
    "    futures.append((smiles, dock_future))\n",
    "\n",
    "print(futures)\n",
    "# wait for all the workflows to complete\n",
    "for smiles, future in futures:\n",
    "    result = future.result()\n",
    "    print(f'Computation for {smiles} succeeded: {result}')\n",
    "    \n",
    "    train_data.append({\n",
    "            'smiles': smiles,\n",
    "            'score': result,\n",
    "            'time': monotonic()\n",
    "    })\n",
    "    smiles_simulated.append(smiles)\n",
    "\n",
    "training_df = pd.DataFrame(train_data)\n",
    "\n",
    "# train model, run inference, and run more simulations\n",
    "for i in range(num_loops):\n",
    "    print(f\"Starting batch {i}\")\n",
    "    m = train_model(training_df)\n",
    "    predictions = run_model(m, search_space['SMILES'])\n",
    "    predictions.sort_values('score', ascending=True, inplace=True) #.head(5)\n",
    "    \n",
    "    train_data = [] \n",
    "    futures = []\n",
    "    for smiles in predictions['smiles'][:5]:\n",
    "        if smiles not in smiles_simulated:\n",
    "            fname = uuid.uuid4().hex\n",
    "\n",
    "            smi_future = parsl_smi_to_pdb(smiles, outputs=[PFile('%s.pdb' % fname)])\n",
    "            element_future = parsl_set_element(smi_future.outputs[0], outputs=[PFile('%s-coords.pdb'% fname)]) \n",
    "            pdbqt_future = parsl_pdb_to_pdbqt(element_future.outputs[0], outputs=[PFile('%s-coords.pdbqt' % fname)])\n",
    "            config_future = parsl_make_autodock_config(PFile(receptor), pdbqt_future.outputs[0], \n",
    "                                             '%s-out.pdb' % fname, outputs=[PFile('%s-config.txt' % fname)])\n",
    "            dock_future = parsl_autodock_vina(config_future.outputs[0])\n",
    "            cleanup(dock_future, smi_future.outputs[0], element_future.outputs[0], pdbqt_future.outputs[0], \n",
    "                    config_future.outputs[0], PFile('%s-out.pdb' % fname))\n",
    "\n",
    "            futures.append((smiles, dock_future))\n",
    "\n",
    "    # print(futures)\n",
    "    # wait for all the workflows to complete\n",
    "    for smiles, future in futures:\n",
    "        result = future.result()\n",
    "        print(f'Computation for {smiles} succeeded: {result}')\n",
    "\n",
    "        train_data.append({\n",
    "                'smiles': smiles,\n",
    "                'score': result,\n",
    "                'time': monotonic()\n",
    "        })\n",
    "        smiles_simulated.append(smiles)\n",
    "                     \n",
    "    training_df = pd.concat((training_df, pd.DataFrame(train_data)), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d88f81e-3808-4be5-8617-5b17f8013302",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plotting progress\n",
    "\n",
    "We can plot our simulations over time. We see in the plot below the docking score (y-axis) vs application time (x-axis). We show a dashed line of the \"best\" docking score discovered to date. You should see a step function improving the best candidate over each iteration. You should also see that the individual points tend to get lower over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c1d6b6-fbe2-4e7e-8a39-2c2cfede6010",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4.5, 3.))\n",
    "\n",
    "ax.scatter(training_df['time'], training_df['score'])\n",
    "ax.step(training_df['time'], training_df['score'].cummin(), 'k--')\n",
    "\n",
    "ax.set_xlabel('Walltime (s)')\n",
    "ax.set_ylabel('Docking Score)')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eab965-8673-49e0-8419-430ec529ef61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:parsldocenv]",
   "language": "python",
   "name": "conda-env-parsldocenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
